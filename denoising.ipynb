{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6864f05-9675-4054-a15d-8db285550a55",
   "metadata": {},
   "source": [
    "# Denoising (DAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69db4ad1-6047-4e3f-8114-db71b30a2cfe",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4766778c-b3df-43fc-ae77-913c4f41501b",
   "metadata": {},
   "source": [
    "## 0. Imports & variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "013cd496-8501-4522-967c-40a5d808dd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as  pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "673ec0b5-631c-467a-a9ef-2c21f2b8d183",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"processed_data/photos/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c67174b-6fdd-499f-a760-ad50e060befe",
   "metadata": {},
   "source": [
    "## 1. Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5463c9d-d618-4d8e-87bf-d6a4a75cfdc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e6c8bdef174b11acd629d5ff8d78ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading and Noising Images:   0%|          | 0/29979 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing aug_photo_5977_0_1039.jpeg: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run ExpandDims: Dst tensor is not initialized. [Op:ExpandDims]\n",
      "Error processing aug_photo_5977_0_5654.jpeg: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run ExpandDims: Dst tensor is not initialized. [Op:ExpandDims]\n",
      "Error processing aug_photo_5978_0_2259.jpeg: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run ExpandDims: Dst tensor is not initialized. [Op:ExpandDims]\n",
      "Error processing aug_photo_5978_0_3069.jpeg: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run ExpandDims: Dst tensor is not initialized. [Op:ExpandDims]\n",
      "Error processing aug_photo_5979_0_3733.jpeg: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run ExpandDims: Dst tensor is not initialized. [Op:ExpandDims]\n",
      "Error processing aug_photo_5979_0_6612.jpeg: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run ExpandDims: Dst tensor is not initialized. [Op:ExpandDims]\n",
      "Error processing aug_photo_5980_0_1206.jpeg: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run ExpandDims: Dst tensor is not initialized. [Op:ExpandDims]\n",
      "Error processing aug_photo_5980_0_3331.jpeg: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run ExpandDims: Dst tensor is not initialized. [Op:ExpandDims]\n",
      "Error processing aug_photo_5981_0_2109.jpeg: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run ExpandDims: Dst tensor is not initialized. [Op:ExpandDims]\n",
      "Error processing aug_photo_5981_0_7368.jpeg: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run ExpandDims: Dst tensor is not initialized. [Op:ExpandDims]\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "def load_and_noisify_images(folder, noise_factor=0.5):\n",
    "    images_list = []\n",
    "    noisy_images_list = []\n",
    "    \n",
    "    # Barre de progression pour le chargement des images\n",
    "    filelist = os.listdir(folder)\n",
    "    for filename in tqdm(filelist, desc=\"Loading and Noising Images\"):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        \n",
    "        try:\n",
    "            # Lire et redimensionner l'image\n",
    "            img = tf.io.read_file(img_path)\n",
    "            img = tf.image.decode_image(img, channels=3, dtype=tf.float32)\n",
    "            img = tf.image.resize(img, [100, 100])\n",
    "            img = img / 255.0  # Normalisation\n",
    "\n",
    "            # Bruitage\n",
    "            noisy = img + noise_factor * tf.random.normal(shape=img.shape, mean=0., stddev=1.)\n",
    "            noisy = tf.clip_by_value(noisy, clip_value_min=0., clip_value_max=1.)\n",
    "            \n",
    "            images_list.append(img)\n",
    "            noisy_images_list.append(noisy)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {str(e)}\")\n",
    "\n",
    "    return tf.stack(images_list), tf.stack(noisy_images_list)\n",
    "\n",
    "# Chemin d'accès au dossier contenant les images\n",
    "folder_path = \"processed_data/photos\"\n",
    "\n",
    "# Chargement et bruitage des images\n",
    "original_images, noisy_images = load_and_noisify_images(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8410e228-97b1-4661-badf-78fa473ddb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(noisy_images, original_images, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adb7d72-f2b4-4828-ada1-db612b196642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_img = Input(shape=(150, 150, 3))\n",
    "\n",
    "# Encodeur\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# Décodeur\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edb11d9-1943-4ac0-b377-ffd5e764ab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(X_train, y_train,\n",
    "                          epochs=50,\n",
    "                          batch_size=128,\n",
    "                          shuffle=True,\n",
    "                          validation_data=(X_valid, y_valid),\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dabb892-892d-4205-b6ac-0af9fd790c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0213824f-3ee0-418a-a823-a822d30cef43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd0311d-6afe-4dc0-a8f0-953c0a618b97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dee7d7-7824-442c-903a-0eeca81ffd2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148dc087-8bb6-452b-b2d8-95ff3eb32d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63a212d-187c-40f6-8137-fca55604b41d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b679ab29-f453-427f-8fe9-f92edc4f0d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358773ff-cdf7-4738-9af7-3bc5a0d49d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c9e3f7-64c2-4faa-bc8d-b7efdd62f644",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'image': list(images_np)})\n",
    "\n",
    "df['height'] = df['image'].apply(lambda x: x.shape[0])\n",
    "df['width'] = df['image'].apply(lambda x: x.shape[1])\n",
    "df['channels'] = df['image'].apply(lambda x: x.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca194f36-e7de-4097-81aa-c0fb1dd9f665",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a0c7bc-4c81-4e94-b2b2-96e280e2d5b7",
   "metadata": {},
   "source": [
    "## 2. Exploration des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8309fa9-88f5-4162-bfe5-c03f87ff27c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_np = images_np.astype(np.float32)\n",
    "images_np /= 255.0\n",
    "\n",
    "print(\"Après normalisation:\")\n",
    "print(\"Valeur minimale:\", images_np.min())\n",
    "print(\"Valeur maximale:\", images_np.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836056c2-66df-4ad5-9825-e03713c4c415",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images = images_np[:5]\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n",
    "\n",
    "for img, ax in zip(sample_images, axes):\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7eee8c-53d1-498d-ac62-6698436cb74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Scatter plot\n",
    "plt.scatter(df['height'], df['width'], alpha=0.6, edgecolors=\"w\", linewidth=0.5)\n",
    "\n",
    "# Configuration du graphique\n",
    "plt.xlabel('Hauteur (pixels)')\n",
    "plt.ylabel('Largeur (pixels)')\n",
    "plt.title('Distribution des dimensions des images')\n",
    "plt.grid(True)\n",
    "\n",
    "# Pour afficher une ligne de référence diagonale (utile si vous voulez voir combien d'images sont carrées)\n",
    "plt.plot([0, max(df['height'])], [0, max(df['width'])], 'r--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b8c0fc-a95b-4da7-9757-864ffceded00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour exécution eager\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "def resize_images_with_tf(image_arrays, target_size):\n",
    "    resized_images = []\n",
    "    input_images = tf.convert_to_tensor(image_arrays, dtype=tf.float32)\n",
    "    batch_resized = tf.image.resize(input_images, target_size)\n",
    "    \n",
    "    resized_images.extend([img.cpu().numpy() if tf.is_tensor(img) else img for img in batch_resized])\n",
    "    return resized_images\n",
    "\n",
    "# Je suppose que la colonne contenant les images s'appelle \"image\" dans votre DataFrame\n",
    "image_arrays = df['image'].tolist()\n",
    "\n",
    "# Redimensionnez les images à 128x128 pixels\n",
    "target_size = (128, 128)\n",
    "resized_images = resize_images_with_tf(image_arrays, target_size)\n",
    "\n",
    "# Convertir la liste des images redimensionnées en DataFrame\n",
    "df_resized = pd.DataFrame({'image': [img.tolist() for img in resized_images]})\n",
    "\n",
    "# Extraire la hauteur et la largeur des images\n",
    "df_resized['height'] = df_resized['image'].apply(lambda img: np.array(img).shape[0])\n",
    "df_resized['width'] = df_resized['image'].apply(lambda img: np.array(img).shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ba2315-f9c0-4d2c-b70f-186f9bd4b768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser la distribution des dimensions\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(df_resized['height'], df_resized['width'], alpha=0.6, edgecolors=\"w\", linewidth=0.5)\n",
    "plt.title(\"Distribution des images en fonction de leur hauteur et de leur largeur (redimensionnées)\")\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Hauteur (pixels)\")\n",
    "plt.ylabel(\"Largeur (pixels)\")\n",
    "plt.plot([0, max(df_resized['height'])], [0, max(df_resized['width'])], 'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c67587-8aec-4e1e-8d93-b2efa88c4da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    filenames = []\n",
    "    \n",
    "    for filename in tqdm(os.listdir(folder), desc=\"Loading images\"):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        \n",
    "        try:\n",
    "            # Lire l'image en couleur (RGB) avec TensorFlow\n",
    "            img = tf.io.read_file(img_path)\n",
    "            img = tf.image.decode_image(img, channels=3)\n",
    "            if img is not None:\n",
    "                images.append(img.numpy())\n",
    "                filenames.append(filename)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {filename}: {e}\")\n",
    "\n",
    "    return images, filenames\n",
    "\n",
    "photos_folder = \"processed_data/photos/\"\n",
    "photos, photo_filenames = load_images_from_folder(photos_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101598a8-6395-4820-b28c-d6cbd5f83a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_to_image(img, noise_factor=0.5):\n",
    "    noisy_img = img + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=img.shape)\n",
    "    return np.clip(noisy_img, 0, 255).astype(np.uint8)\n",
    "\n",
    "noisy_photos = [add_noise_to_image(photo) for photo in tqdm(photos, desc=\"Adding noise\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c0654c-9fa3-4109-b0db-096de4c75a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_photos_folder = \"processed_data/noisy_photos/\"\n",
    "os.makedirs(noisy_photos_folder, exist_ok=True)\n",
    "\n",
    "for noisy_photo, filename in tqdm(zip(noisy_photos, photo_filenames), total=len(noisy_photos), desc=\"Saving noisy images\"):\n",
    "    output_path = os.path.join(noisy_photos_folder, filename)\n",
    "    tf.io.write_file(output_path, tf.image.encode_jpeg(noisy_photo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351048bb-b90e-4921-9a0d-deaad4333073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir votre liste de photos bruitées en DataFrame\n",
    "df_noisy = pd.DataFrame({'image': noisy_photos})\n",
    "\n",
    "def display_images(original, noisy, num=10):\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(num):\n",
    "        # Afficher les images originales\n",
    "        ax = plt.subplot(2, num, i + 1)\n",
    "        plt.imshow(original[i])\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        \n",
    "        # Afficher les images bruitées\n",
    "        ax = plt.subplot(2, num, i + 1 + num)\n",
    "        plt.imshow(noisy[i])\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "\n",
    "# Extraire des échantillons des images originales et bruitées pour la visualisation\n",
    "original_images = photos[:10]\n",
    "noisy_images = df_noisy['image'].tolist()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb523af3-a18c-4b0d-a9ec-52cf764e0f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images(original_images, noisy_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409be1fc-c826-4f83-a7f8-d85b9d4864b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500  # réduire encore plus la taille des lots\n",
    "\n",
    "for i in range(0, len(df_noisy), batch_size):\n",
    "    df_noisy.loc[i:i+batch_size-1, 'image'] = df_noisy.iloc[i:i+batch_size]['image'].transform(lambda x: (x / 255.).astype(np.float32))\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    df.loc[i:i+batch_size-1, 'image'] = df.iloc[i:i+batch_size]['image'].transform(lambda x: (x / 255.).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf59ed5-0aee-4a66-a698-b3002c942d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(df_noisy['image'].tolist(), df['image'].tolist(), test_size=0.15, random_state=42)\n",
    "\n",
    "# Convertir les listes en arrays numpy pour l'entraînement\n",
    "X_train = np.array(X_train)\n",
    "X_valid = np.array(X_valid)\n",
    "y_train = np.array(y_train)\n",
    "y_valid = np.array(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aeede7-46a1-4345-9fa8-64ef58adea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_img = Input(shape=(150, 150, 3))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "# Encodeur\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# Décodeur\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cb54ac-bee6-460b-90f4-f8db22c81f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(X_train, y_train,\n",
    "                          epochs=50,\n",
    "                          batch_size=128,\n",
    "                          shuffle=True,\n",
    "                          validation_data=(X_valid, y_valid),\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665fa6a0-afca-4d7f-99bf-320189d91e97",
   "metadata": {},
   "source": [
    "## 3. Pré-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4549ff-bb57-4e74-a08b-eede716e793b",
   "metadata": {},
   "source": [
    "## 4. Création du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835c5b03-3725-43c0-8b96-2c63581d2f4d",
   "metadata": {},
   "source": [
    "## 5. Entraînement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cad346-63bf-4c4d-b7f7-047dfc787976",
   "metadata": {},
   "source": [
    "## 6. Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46f59a4-5155-45d1-8f18-c442c16fbb09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b260961d-7c35-483e-a0a1-ae2993eabb4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f55e490-d844-42b8-8054-aa9c079137bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df8a184-c1e6-4aa3-87a4-9ee3037ce753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead486f7-94ca-49f0-af2c-966b8c60090f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:projet] *",
   "language": "python",
   "name": "conda-env-projet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
